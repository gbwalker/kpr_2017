---
title: "Replication: King, Pan, Roberts (2017)"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(igraph)
library(extrafont)
library(lubridate)
```

# Abstract

Here I replicate the figures in the original paper.

# Figure 1. Network Structure of Leaked Email Correspondents

```{r fig1, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.dim=c(6,6), fig.align='center'}

# Figure 1.
# Create a graph of the email network using igraph.

# Read in the network CSV file generated from the code in Figure1.R.
# Note that the code that manipulates the initial leaked files is
# uncommented in the replication file, since it provides the preprocessed
# Network.csv for making this graph.

network <- read.csv("data/Network.csv", header = T) %>% 
  as.matrix()

# Set the row names and delete the row.

row.names(network) <- network[,1]
network <- network[,-1]

diag(network) <- 0
set.seed(3487)
g <- graph.adjacency(network, mode="undirected")
g <- simplify(g)

l <-layout.fruchterman.reingold(g) 
l[,2] <- l[,2]*-1

# Set the vertices of the graph.

V(g)$label <- ""
V(g)$size <- 2
V(g)$label.cex <- .1

plot(g, layout=l)
text(.55,.1,"Commentators Reporting to \n Zhanggong Internet \n Propaganda Office")
text(x =.25, y = -.05, '{', srt = 45, cex = 2, family = 'LM Roman 10')
arrows(-.55,-.55,-.1,-.45, lwd=3)
text(-.9,-.56,"Zhanggong Internet \n  Propaganda Office")
text(0,.95,"Higher Level Offices \n Reported To")
text(x = 0, y = 0.8, '{', srt = 90, cex = 2, family = 'LM Roman 10')
```

***

*Note*: Circles are email correspondents, and edges (lines) indicate email correspondence. Most of the correspondence is toward the center of the flower-like structure (to the Zhanggong Internet Propaganda Office and then out from that office to higher-level offices.

\pagebreak

# Figure 2. Time Series of 43,757 Known 50c Social Media Posts with Qualitative Summaries of the Content of Volume Bursts

```{r fig2, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, cache=TRUE, fig.dim=c(7,7), fig.align='center'}

# Figure 2.
# A time series of the number of known 50c posts.

# Read in the data.
# Note that read_csv is MUCH faster than read.csv and it automatically displays the Chinese text.

# posts <- read.csv("data/posts_all.csv", header=T, encoding="UTF-8")
posts <- read_csv("data/posts_all.csv")

# Make a table of all the post dates.

postcount <- table(posts$PostDate)

# Make the sequence of dates from the posts.

dateseq <- seq(min(posts$PostDate), max(posts$PostDate), by="day")
dateseq <- dateseq[!dateseq%in%as.Date(names(postcount))]
zeros <- rep(0, length(dateseq))
names(zeros) <- dateseq
postcount <- c(postcount, zeros)
postcount <- postcount[order(as.Date(names(postcount)))]

# Make a list of months for the x-axis labels.

months <- seq(as.Date("2013-01-01"), as.Date("2014-12-01"), by="month")
monthslab <- months(months, abbreviate=T)

# Plot the time plot.

plot(as.Date(names(postcount)),as.vector(postcount), type="l", ylab="Count of Posts",xlab="Date (Jan 2013 - Dec 2014)",xaxt="n",ylim=c(0,4000))

axis(1,at=months,labels=monthslab)

# Add labels for suggested post triggers.

text(as.Date("2013-04-07"),3600,"1. Qingming\nfestival\n(April)", col="red")
text(as.Date("2013-05-23"),1400,"2. China\nDream\n(May)", col="red")
text(as.Date("2013-07-01"),2000,"3. Shanshan\nriots (July)", col="red")
arrows(as.Date("2013-07-01"), 1800, as.Date("2013-07-01"), 1050, col="red", length=0.1)
text(as.Date("2013-11-09"), 600, "4. 3rd plenum\nCCP 18th\nCongress (Nov)", col="red")
text(as.Date("2014-02-12"), 1150, "5. Two meetings\n(Feb)", col="red")
arrows(as.Date("2014-02-12"), 950, as.Date("2014-02-12"), 600, col="red", length=0.1)
text(as.Date("2014-05-09"),2200,"6. Urumqi rail\nexplosion (May)", col="red")
text(as.Date("2014-07-15"),1300,"7. Gov't\nforum,\npraise\ncentral\nsubsidy\n(Jul-Aug)", col="red")

segments(as.Date("2014-07-15"),750,as.Date("2014-07-15"),650, col="red")
segments(as.Date("2014-06-15"),650,as.Date("2014-08-30"), col="red")
segments(as.Date("2014-06-15"),650,as.Date("2014-06-15"),600, col="red")
segments(as.Date("2014-08-30"),650,as.Date("2014-08-30"),600, col="red")
text(as.Date("2014-10-08"),3000,"8. Martyr's\nDay\n(Oct)", col="red", pos=2)
```

\pagebreak

# Figure 3. Content of Leaked and Inferred 50c Posts, by substantive category

```{r fig3data, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, cache=TRUE, results=FALSE}

# Figure 3.
# Results of the ReadMe analysis.

# Read in all the CSVs for the figure.
# Note that the replication code changes the working directory and this does not.

results1 <- read.csv("data/figure_3/Analysis1/ReadMeBootResults.csv")
results2 <- read.csv("data/figure_3/Analysis2/ReadMeBootResults.csv")
selectresults <- read.csv("data/figure_3/Analysis2/ReadMeBootResults_Exclusive.csv")
notselectresults <- read.csv("data/figure_3/Analysis2/ReadMeBootResults_Ordinary.csv")
results3 <- read.csv("data/figure_3/Analysis3/ReadMeBootResults.csv")
results4 <- read.csv("data/figure_3/Analysis4/ReadMeBootResults.csv")

# Normalize to remove Other category (Category 2).
# Note that none of the variables have names (!).

results1 <- results1/(1-results1[,2])
results2 <- results2/(1-results2[,2])
results3 <- results3/(1-results3[,2])
results4 <- results4/(1-results4[,2])
selectresults <- selectresults/(1-selectresults[,2])
notselectresults <- notselectresults/(1-notselectresults[,2])

# Make point estimates for each category.

# Analysis 1
apply(results1[,c(1,3:6)],2,mean)
# Analysis 2
apply(results2[,c(1,3:6)],2,mean)
# Ordinary
apply(notselectresults[,c(1,3:6)],2,mean)
# Exclusive
apply(selectresults[,c(1,3:6)],2,mean)
# Analysis 3
apply(results3[,c(1,3:6)],2,mean)
# Analysis 4
apply(results4[,c(1,3:6)],2,mean)

```

```{r fig3plot, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, cache=TRUE, fig.dim=c(10,7)}

# Plot the results.

plot(c(1,3,5,4,2), apply(results1[,c(1,3:6)], 2, mean), xaxt = "n", ylim = c(0,1), xlab="",
     ylab="Proportion", pch=16, xlim=c(0.5,6.1))

segments(c(1,3,5,4,2), apply(results1[,c(1,3:6)],2, function (x)
    quantile(x,.975)), c(1,3,5,4,2),apply(results1[,c(1,3:6)],2, function (x)
      quantile(x,.025)))

points(c(1,3,5,4,2)+.1, apply(results2[,c(1,3:6)],2,mean), pch=17)
segments(c(1,3,5,4,2) +.1, apply(results2[,c(1,3:6)],2, function (x)
  quantile(x,.975)), c(1,3,5,4,2)+.1,apply(results2[,c(1,3:6)],2, function (x)
    quantile(x,.025)), lty=2)

points(c(1,3,5,4,2)+.2, apply(selectresults[,c(1,3:6)],2,mean), pch=7, col="red")
segments(c(1,3,5,4,2) +.2, apply(selectresults[,c(1,3:6)],2, function (x)
  quantile(x,.975)), c(1,3,5,4,2)+.2,apply(selectresults[,c(1,3:6)],2, function (x)
    quantile(x,.025)), lty=2, col="red")

points(c(1,3,5,4,2)+.3, apply(notselectresults[,c(1,3:6)],2,mean), pch=8, col="red")
segments(c(1,3,5,4,2) +.3, apply(notselectresults[,c(1,3:6)],2, function (x)
  quantile(x,.975)), c(1,3,5,4,2)+.3,apply(notselectresults[,c(1,3:6)],2, function (x)
    quantile(x,.025)), lty=2, col="red")

points(c(1,3,5,4,2)+.4, apply(results3[,c(1,3:6)],2,mean), pch=4)
segments(c(1,3,5,4,2) +.4, apply(results3[,c(1,3:6)],2, function (x)
  quantile(x,.975)), c(1,3,5,4,2)+.4,apply(results3[,c(1,3:6)],2, function (x)
    quantile(x,.025)), lty=3)

points(c(1,3,5,4,2)+.5, apply(results4[,c(1,3:6)],2,mean), pch=5)
segments(c(1,3,5,4,2) +.5, apply(results4[,c(1,3:6)],2, function (x)
  quantile(x,.975)), c(1,3,5,4,2)+.5,apply(results4[,c(1,3:6)],2, function (x)
    quantile(x,.025)), lty=5)

# Write the legend.

legend(.4,1, c("Leaked e-mails, all sites", "Leaked accounts, Weibo",
                "Leaked accounts, exclusive",
                "Leaked accounts, ordinary", "Within county prediction, all posts",  "Out of county prediction"),
       lty=c(1,2,2,2,3,4), pch=c(16,17,7,8,4,5), col=c(rep("black",2),
                                                       rep("red",2), rep("black",2)))

text(1.8, .17, "Argumentative Praise \n or Criticism")
text(.9, 0.08, "Taunting of Foreign \n Countries")
text(5.5, .8, "Cheerleading")
text(4.8, .17, "Factual \n Reporting")
text(3.2, 0, "Non-argumentative \n Praise or Suggestions")
```